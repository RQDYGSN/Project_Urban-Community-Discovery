{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import karateclub\n",
    "from tkinter import _flatten\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MGCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate $K$ and $M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "K = random.randint(1, 10)\n",
    "M = random.randint(1, 100)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gnerate Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点总数 360\n"
     ]
    }
   ],
   "source": [
    "average_cluster_size = random.randint(20, 40)\n",
    "\n",
    "center_x_list = []\n",
    "center_y_list = []\n",
    "for i in range(K):\n",
    "    center_x_list.append(round(10*random.random(), 4))\n",
    "    center_y_list.append(round(10*random.random(), 4))\n",
    "node_groundtruth = {}\n",
    "node_location = {}\n",
    "idx = 0\n",
    "for i in range(K):\n",
    "    for j in range(average_cluster_size):\n",
    "        node_groundtruth[idx] = i\n",
    "        node_location[idx] = [center_x_list[i] + round(random.gauss(0, 1), 4), center_y_list[i] + round(random.gauss(0, 1), 4)]\n",
    "        idx = idx + 1\n",
    "N = len(node_groundtruth)\n",
    "print('节点总数', N)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(list(range(N)))\n",
    "\n",
    "ground_truth = {}\n",
    "for k, v in node_groundtruth.items():\n",
    "    if v not in ground_truth:\n",
    "        ground_truth[v] = [k]\n",
    "    else:\n",
    "        ground_truth[v].append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. k-nearest neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fa9b06025d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_np = np.array(list(node_location.values()))\n",
    "x_np = loc_np[:, 0].reshape((1, -1))\n",
    "y_np = loc_np[:, 1].reshape((1, -1))\n",
    "distance_np = np.square(x_np - x_np.T)+np.square(y_np - y_np.T)\n",
    "k_nearest = {}\n",
    "k = int(average_cluster_size/2)\n",
    "for i in range(N):\n",
    "    k_near_pre = list(np.argsort(distance_np[i])[:k+1:])\n",
    "    k_near_pre.remove(i)\n",
    "    k_nearest[i] = k_near_pre\n",
    "for i in range(N):\n",
    "    for j in k_nearest[i]:\n",
    "        G.add_edge(i, j, weight = np.exp(-1/2*distance_np[i, j]))\n",
    "        \n",
    "G.to_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate $f_{k, m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "omega = 1/K*np.ones(K)\n",
    "beta = 1/M*np.ones(M)\n",
    "F = omega.reshape((1, -1))*beta.reshape((-1, 1))\n",
    "F = F*K*M\n",
    "# F [M, K]\n",
    "print(average_cluster_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Allocate for $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((N, M))\n",
    "for i in range(M):\n",
    "    for j in range(K):\n",
    "        tmp = np.random.dirichlet(np.ones(average_cluster_size), size=1)*F[i, j]\n",
    "        X[j*average_cluster_size:(j+1)*average_cluster_size:, i] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. for Algorithm Process & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485\n",
      "0.496\n",
      "0.328\n"
     ]
    }
   ],
   "source": [
    "# 1. DANMF\n",
    "\n",
    "model1 = karateclub.DANMF()\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "0.309\n",
      "0.273\n"
     ]
    }
   ],
   "source": [
    "# 2. NNSED\n",
    "\n",
    "model1 = karateclub.NNSED(dimensions=K)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "0.484\n",
      "0.361\n"
     ]
    }
   ],
   "source": [
    "# 3. MNMF\n",
    "\n",
    "model1 = karateclub.MNMF(clusters=K)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383\n",
      "0.263\n",
      "0.245\n"
     ]
    }
   ],
   "source": [
    "# 4. BigClam\n",
    "\n",
    "model1 = karateclub.BigClam(dimensions=K)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.238\n",
      "0.138\n",
      "0.137\n"
     ]
    }
   ],
   "source": [
    "# 5. SNMF\n",
    "\n",
    "model1 = karateclub.SymmNMF(dimensions=K)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538\n",
      "0.506\n",
      "0.395\n"
     ]
    }
   ],
   "source": [
    "# 6. GEMSEC\n",
    "\n",
    "model1 = karateclub.GEMSEC(dimensions=K)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.401\n",
      "0.532\n",
      "0.273\n"
     ]
    }
   ],
   "source": [
    "# 7. SCD\n",
    "\n",
    "model1 = karateclub.SCD()\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172\n",
      "0.049\n",
      "0.094\n"
     ]
    }
   ],
   "source": [
    "# 8. LPA\n",
    "\n",
    "model1 = karateclub.LabelPropagation(seed=10, iterations=100)\n",
    "model1.fit(G)\n",
    "cluster_membership = model1.get_memberships()\n",
    "clusters = cluster_membership\n",
    "labels_pred = list(_flatten(list(clusters.values())))\n",
    "partition = dict(zip(list(range(len(labels_pred))), labels_pred))\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573\n",
      "0.527\n",
      "0.434\n"
     ]
    }
   ],
   "source": [
    "# 9. Louvain\n",
    "\n",
    "partition = community.best_partition(G, weight='weight')\n",
    "labels_pred = partition\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 ; soft_mod:  0.003017 ; loss_cons:  0.104492 ; loss_clus:  0.0\n",
      "Epoch:  10 ; soft_mod:  0.006028 ; loss_cons:  0.064328 ; loss_clus:  0.962183\n",
      "Epoch:  20 ; soft_mod:  0.034588 ; loss_cons:  0.069634 ; loss_clus:  1.078709\n",
      "Epoch:  30 ; soft_mod:  0.051057 ; loss_cons:  0.06526 ; loss_clus:  0.959512\n",
      "Epoch:  40 ; soft_mod:  0.066604 ; loss_cons:  0.051826 ; loss_clus:  0.900025\n",
      "Epoch:  50 ; soft_mod:  0.141815 ; loss_cons:  0.042637 ; loss_clus:  0.840196\n",
      "Epoch:  60 ; soft_mod:  0.285952 ; loss_cons:  0.049788 ; loss_clus:  0.849018\n",
      "Epoch:  70 ; soft_mod:  0.366723 ; loss_cons:  0.045985 ; loss_clus:  0.857807\n",
      "Epoch:  80 ; soft_mod:  0.476688 ; loss_cons:  0.029378 ; loss_clus:  0.900582\n",
      "Epoch:  90 ; soft_mod:  0.545812 ; loss_cons:  0.037601 ; loss_clus:  1.006857\n",
      "Epoch:  100 ; soft_mod:  0.613745 ; loss_cons:  0.029818 ; loss_clus:  1.198673\n",
      "Epoch:  110 ; soft_mod:  0.645755 ; loss_cons:  0.034505 ; loss_clus:  1.476215\n",
      "Epoch:  120 ; soft_mod:  0.681986 ; loss_cons:  0.037807 ; loss_clus:  1.748885\n",
      "Epoch:  130 ; soft_mod:  0.683689 ; loss_cons:  0.040501 ; loss_clus:  2.106833\n",
      "Epoch:  140 ; soft_mod:  0.685252 ; loss_cons:  0.041855 ; loss_clus:  2.485706\n",
      "Epoch:  150 ; soft_mod:  0.688324 ; loss_cons:  0.038233 ; loss_clus:  2.952481\n",
      "Epoch:  160 ; soft_mod:  0.689268 ; loss_cons:  0.046647 ; loss_clus:  3.375669\n",
      "Epoch:  170 ; soft_mod:  0.688302 ; loss_cons:  0.053546 ; loss_clus:  3.738927\n",
      "Epoch:  180 ; soft_mod:  0.688397 ; loss_cons:  0.058224 ; loss_clus:  4.062688\n",
      "Epoch:  190 ; soft_mod:  0.690069 ; loss_cons:  0.061007 ; loss_clus:  4.287405\n",
      "Epoch:  200 ; soft_mod:  0.69016 ; loss_cons:  0.064592 ; loss_clus:  4.403714\n",
      "Epoch:  210 ; soft_mod:  0.690232 ; loss_cons:  0.07049 ; loss_clus:  4.385275\n",
      "Epoch:  220 ; soft_mod:  0.68891 ; loss_cons:  0.077583 ; loss_clus:  4.275323\n",
      "Epoch:  230 ; soft_mod:  0.689957 ; loss_cons:  0.080074 ; loss_clus:  4.111215\n",
      "Epoch:  240 ; soft_mod:  0.689185 ; loss_cons:  0.086343 ; loss_clus:  3.877365\n"
     ]
    }
   ],
   "source": [
    "# Ours\n",
    "partition = MGCF.main(clusters_number=K, feature=X, multi_graph=[G], alpha_1=1, alpha_2=0.1, alpha_3=0.01, weight_list=[1], alpha=2, epoch_num=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n",
      "0.541\n",
      "0.364\n"
     ]
    }
   ],
   "source": [
    "labels_pred = partition\n",
    "partition_2 = {}\n",
    "for i in range(len(labels_pred)):\n",
    "    if labels_pred[i] not in partition_2:\n",
    "        partition_2[labels_pred[i]] = [i]\n",
    "    else:\n",
    "        partition_2[labels_pred[i]].append(i)\n",
    "        \n",
    "print(round(fscore(partition_2, ground_truth), 3))\n",
    "print(round(nmi(partition_2, ground_truth), 3))\n",
    "print(round(jaccard_similarity(partition_2, ground_truth), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition: cluster -- node_list\n",
    "# ground_truth: node -- cluster\n",
    "\n",
    "def nmi(partition, ground_truth):\n",
    "    node_num = 0\n",
    "    for k, v in partition.items():\n",
    "        node_num += len(v)\n",
    "\n",
    "    hx = 0\n",
    "    for k, v in partition.items():\n",
    "        p = len(v)/node_num\n",
    "        hx += p*np.log2(1/(p+0.0000001))\n",
    "\n",
    "    hy = 0\n",
    "    for k, v in ground_truth.items():\n",
    "        p = len(v)/node_num\n",
    "        hy += p*np.log2(1/(p+0.0000001))\n",
    "\n",
    "    ixy = 0\n",
    "    for k1, v1 in partition.items():\n",
    "        for k2, v2 in ground_truth.items():\n",
    "            pxy = len(set(v1) & set(v2))/node_num\n",
    "            px = len(v1)/node_num\n",
    "            py = len(v2)/node_num\n",
    "            ixy += pxy*np.log2((pxy+0.0000001)/(px+0.0000001)/(py+0.0000001))\n",
    "\n",
    "    return ixy*2/(hx+hy)\n",
    "\n",
    "\n",
    "def fscore(partition, ground_truth):\n",
    "    F = 0\n",
    "    count = 0\n",
    "    for k1, v1 in partition.items():\n",
    "        f = 0\n",
    "        s1 = set(v1)\n",
    "        for k2, v2 in ground_truth.items():\n",
    "            s2 = set(v2)\n",
    "            intersection = s1 & s2\n",
    "            precision = len(intersection)/len(s1)\n",
    "            recall = len(intersection)/len(s2)\n",
    "            if precision*recall != 0:\n",
    "                tmp = 2*precision*recall/(precision + recall)\n",
    "                if tmp > f: f = tmp\n",
    "            else:\n",
    "                continue\n",
    "        F += f\n",
    "        count += 1\n",
    "    F = F/count\n",
    "    return F\n",
    "\n",
    "\n",
    "def jaccard_similarity(partition, ground_truth):\n",
    "    JS = 0\n",
    "    count = 0\n",
    "    for k1, v1 in partition.items():\n",
    "        js = 0\n",
    "        s1 = set(v1)\n",
    "        for k2, v2 in ground_truth.items():\n",
    "            s2 = set(v2)\n",
    "            tmp = len(s1 & s2)/len(s1 | s2)\n",
    "            if tmp>js: js = tmp\n",
    "        JS += js\n",
    "        count += 1\n",
    "    JS = JS/count\n",
    "    return JS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
